"use client";

import { useState, useRef, useCallback } from "react";

interface UseVoiceRecorderOptions {
  /** æœ€ç»ˆç¡®è®¤çš„æ–‡æœ¬å›è°ƒï¼ˆç”¨æˆ·åœé¡¿åç¡®è®¤çš„ç»“æœï¼‰ */
  onResult?: (text: string, isFinal: boolean) => void;
  /** å®æ—¶ä¸´æ—¶ç»“æœå›è°ƒï¼ˆæ­£åœ¨è¯†åˆ«ä¸­çš„æ–‡æœ¬ï¼Œç”¨äºå®æ—¶æ˜¾ç¤ºï¼‰ */
  onInterimResult?: (text: string) => void;
  onError?: (error: string) => void;
  language?: string;
  /** æ˜¯å¦è‡ªåŠ¨å»é‡ï¼ˆé˜²æ­¢é‡å¤æ·»åŠ ç›¸åŒæ–‡æœ¬ï¼‰ */
  preventDuplicates?: boolean;
}

interface UseVoiceRecorderReturn {
  isRecording: boolean;
  isSupported: boolean;
  startRecording: () => void;
  stopRecording: () => void;
  error: string | null;
}

/**
 * è¯­éŸ³è½¬æ–‡å­— Hook - é’ˆå¯¹è‹±è¯­å­¦ä¹ ä¼˜åŒ–
 * 
 * å·¥ä½œæµç¨‹ï¼š
 * 1. å®æ—¶æ˜¾ç¤ºä¸´æ—¶è¯†åˆ«ç»“æœï¼ˆç°è‰²/æ–œä½“ï¼‰- onInterimResult
 * 2. ç”¨æˆ·åœé¡¿åï¼Œä¸´æ—¶ç»“æœå˜ä¸ºæœ€ç»ˆç¡®è®¤ç»“æœ - onResult(text, true)
 * 3. ç»§ç»­è¯†åˆ«æ–°çš„ä¸´æ—¶ç»“æœï¼Œè¿½åŠ åˆ°å·²ç¡®è®¤çš„æ–‡æœ¬å
 * 
 * è¿™ç§æ–¹å¼æä¾›æœ€ä½³çš„å®æ—¶åé¦ˆä½“éªŒ
 */
export function useVoiceRecorder({
  onResult,
  onInterimResult,
  onError,
  language = "en-US",
  preventDuplicates = true,
}: UseVoiceRecorderOptions = {}): UseVoiceRecorderReturn {
  const [isRecording, setIsRecording] = useState(false);
  const [error, setError] = useState<string | null>(null);
  const recognitionRef = useRef<any>(null);
  const lastFinalResultRef = useRef<string>("");
  const accumulatedFinalTextRef = useRef<string>("");
  const isStoppingRef = useRef<boolean>(false);

  const isSupported = typeof window !== "undefined" && 
    ("webkitSpeechRecognition" in window || "SpeechRecognition" in window);

  /**
   * æ¸…ç†è¯†åˆ«å¯¹è±¡ï¼Œç¡®ä¿å®Œå…¨åœæ­¢
   */
  const cleanupRecognition = useCallback(() => {
    if (recognitionRef.current) {
      try {
        // ç§»é™¤æ‰€æœ‰äº‹ä»¶ç›‘å¬å™¨ï¼Œé˜²æ­¢åœ¨æ¸…ç†è¿‡ç¨‹ä¸­è§¦å‘äº‹ä»¶
        recognitionRef.current.onstart = null;
        recognitionRef.current.onresult = null;
        recognitionRef.current.onerror = null;
        recognitionRef.current.onend = null;
        
        // å°è¯•åœæ­¢è¯†åˆ«
        if (recognitionRef.current.state === "recording" || recognitionRef.current.state === "starting") {
          recognitionRef.current.stop();
        }
      } catch (err) {
        // å¿½ç•¥æ¸…ç†è¿‡ç¨‹ä¸­çš„é”™è¯¯
        console.warn("Error during recognition cleanup:", err);
      } finally {
        recognitionRef.current = null;
      }
    }
    isStoppingRef.current = false;
  }, []);

  const startRecording = useCallback(() => {
    if (!isSupported) {
      const errorMsg = "Speech recognition not supported in this browser";
      setError(errorMsg);
      onError?.(errorMsg);
      return;
    }

    // å¦‚æœæ­£åœ¨å½•éŸ³ï¼Œå…ˆåœæ­¢
    if (recognitionRef.current) {
      const currentState = recognitionRef.current.state;
      if (currentState === "recording" || currentState === "starting") {
        cleanupRecognition();
        setIsRecording(false);
        return;
      }
    }

    // æ¸…ç†æ—§çš„è¯†åˆ«å¯¹è±¡
    cleanupRecognition();

    setError(null);
    setIsRecording(true);
    lastFinalResultRef.current = "";
    accumulatedFinalTextRef.current = "";
    isStoppingRef.current = false;

    try {
      // ä½¿ç”¨ Web Speech API è¿›è¡Œå®æ—¶è¯­éŸ³è¯†åˆ«
      const SpeechRecognition = (window as any).SpeechRecognition || (window as any).webkitSpeechRecognition;
      const recognition = new SpeechRecognition();
      
      recognition.continuous = true;
      recognition.interimResults = true; // â­ å¯ç”¨ä¸´æ—¶ç»“æœï¼Œå®ç°å®æ—¶åé¦ˆ
      recognition.lang = language;
      recognition.maxAlternatives = 1;

      recognition.onstart = () => {
        console.log("âœ… Speech recognition started");
        isStoppingRef.current = false;
      };

      recognition.onresult = (event: any) => {
        // å¦‚æœæ­£åœ¨åœæ­¢ï¼Œå¿½ç•¥ç»“æœ
        if (isStoppingRef.current) {
          return;
        }

        let interimTranscript = "";
        let finalTranscript = "";

        // â­ åªå¤„ç†æ–°çš„è¯†åˆ«ç»“æœï¼ˆä» resultIndex å¼€å§‹ï¼‰ï¼Œé¿å…é‡å¤å¤„ç†å†å²ç»“æœ
        for (let i = event.resultIndex; i < event.results.length; i++) {
          const transcript = event.results[i][0].transcript;
          
          if (event.results[i].isFinal) {
            // æœ€ç»ˆç¡®è®¤çš„ç»“æœ
            finalTranscript += transcript;
          } else {
            // ä¸´æ—¶ç»“æœï¼ˆæ­£åœ¨è¯†åˆ«ä¸­ï¼‰
            interimTranscript += transcript;
          }
        }

        // å¤„ç†ä¸´æ—¶ç»“æœ - å®æ—¶æ˜¾ç¤º
        if (interimTranscript) {
          console.log("ğŸ’¬ Interim:", interimTranscript);
          onInterimResult?.(interimTranscript);
        }

        // å¤„ç†æœ€ç»ˆç»“æœ - ç¡®è®¤å¹¶è¿½åŠ 
        if (finalTranscript) {
          // é˜²é‡å¤é€»è¾‘
          if (preventDuplicates && finalTranscript === lastFinalResultRef.current) {
            console.log("â­ï¸ Skip duplicate:", finalTranscript);
            return;
          }
          
          lastFinalResultRef.current = finalTranscript;
          accumulatedFinalTextRef.current += finalTranscript;
          
          console.log("âœ… Final:", finalTranscript);
          console.log("ğŸ“ Accumulated:", accumulatedFinalTextRef.current);
          
          // å›è°ƒæœ€ç»ˆç»“æœ
          onResult?.(finalTranscript, true);
        }
      };

      recognition.onerror = (event: any) => {
        // å¦‚æœæ­£åœ¨åœæ­¢ï¼Œå¿½ç•¥é”™è¯¯
        if (isStoppingRef.current) {
          return;
        }

        console.error("âŒ Speech recognition error:", event.error);
        
        // å¯¹äºæŸäº›é”™è¯¯ï¼Œä¸æ˜¾ç¤ºé”™è¯¯æ¶ˆæ¯ï¼Œå…è®¸è‡ªåŠ¨æ¢å¤
        const shouldShowError = !["no-speech", "aborted"].includes(event.error);
        
        if (shouldShowError) {
          // å‹å¥½çš„é”™è¯¯æ¶ˆæ¯
          let errorMsg = "Speech recognition error";
          switch (event.error) {
            case "audio-capture":
              errorMsg = "No microphone found. Please check your device.";
              break;
            case "not-allowed":
              errorMsg = "Microphone permission denied. Please allow access.";
              break;
            case "network":
              errorMsg = "Network error. Please check your connection.";
              break;
            default:
              errorMsg = `Speech recognition error: ${event.error}`;
          }
          
          setError(errorMsg);
          onError?.(errorMsg);
        } else {
          // å¯¹äº no-speech å’Œ abortedï¼Œé™é»˜å¤„ç†ï¼Œä¸æ˜¾ç¤ºé”™è¯¯
          console.log("â„¹ï¸ Speech recognition:", event.error === "no-speech" 
            ? "No speech detected (this is normal if you stop quickly)" 
            : "Recognition aborted");
        }
        
        // é”™è¯¯åè‡ªåŠ¨åœæ­¢
        setIsRecording(false);
      };

      recognition.onend = () => {
        console.log("ğŸ›‘ Speech recognition ended");
        
        // åªæœ‰åœ¨éä¸»åŠ¨åœæ­¢çš„æƒ…å†µä¸‹æ‰æ¸…ç†
        if (!isStoppingRef.current && recognitionRef.current === recognition) {
          setIsRecording(false);
          lastFinalResultRef.current = "";
          accumulatedFinalTextRef.current = "";
          recognitionRef.current = null;
        }
      };

      recognitionRef.current = recognition;
      recognition.start();
    } catch (err) {
      const errorMsg = "Failed to start speech recognition";
      console.error(errorMsg, err);
      setError(errorMsg);
      onError?.(errorMsg);
      setIsRecording(false);
      cleanupRecognition();
    }
  }, [isSupported, language, onResult, onInterimResult, onError, preventDuplicates, cleanupRecognition]);

  const stopRecording = useCallback(() => {
    if (!recognitionRef.current) {
      setIsRecording(false);
      return;
    }

    isStoppingRef.current = true;
    setIsRecording(false);

    try {
      // åœæ­¢è¯†åˆ«
      if (recognitionRef.current.state === "recording" || recognitionRef.current.state === "starting") {
        recognitionRef.current.stop();
      }
    } catch (err) {
      console.warn("Error stopping recognition:", err);
    }

    // å»¶è¿Ÿæ¸…ç†ï¼Œç¡®ä¿ onend äº‹ä»¶èƒ½å¤Ÿæ­£å¸¸è§¦å‘
    setTimeout(() => {
      cleanupRecognition();
    }, 100);
  }, [cleanupRecognition]);

  return {
    isRecording,
    isSupported,
    startRecording,
    stopRecording,
    error,
  };
}
